{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 循环神经网络从零开始实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from d2l import torch as d2l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 独热编码\n",
    "F.one_hot(torch.tensor([0,1]),28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).reshape(2,5)\n",
    "F.one_hot(X.T,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 单层循环神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#假设一个文字数据，序列长为3\n",
    "inputs=torch.randn((3,50,10)) #vocal_size,batch_size,input_size\n",
    "rnn1=nn.RNN(input_size=10,hidden_size=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 50, 20])\n",
      "torch.Size([1, 50, 20])\n"
     ]
    }
   ],
   "source": [
    "outputs1,hn1=rnn1(inputs)\n",
    "print(outputs1.shape)\n",
    "print(hn1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深度循环神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs3=torch.randn((3,50,10)) #vocal_size,batch_size,input_size\n",
    "drnn1=nn.RNN(input_size=10,num_layers=4,hidden_size=20)\n",
    "outputs3,hn3=drnn1(inputs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs3.shape\n",
    "outputs3[-1,:,:]\n",
    "hn3.shape \n",
    "hn3[-1,:,:]\n",
    "# output与hn有交集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n.RNN的简单实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 输入层有100个神经元，输出层有3个（简单情感分析的三分类任务）\n",
    "- 每个隐藏层有256个神经元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对最终结果进行分析\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN(nn.Module):\n",
    "    def __init__(self,input_size=100,hidden_size=256,num_layers=4,output_size=3):\n",
    "        super(myRNN,self).__init__()\n",
    "        #创建一个RNN模块\n",
    "        self.rnn=nn.RNN(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)\n",
    "        #输出层单独创建\n",
    "        self.fc=nn.Linear(in_features=hidden_size,out_features=output_size)\n",
    "\n",
    "    def forward(self,X):\n",
    "        output,hn=self.rnn(X)\n",
    "        predict=self.fc(output[-1,:,:])\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myRNN(\n",
      "  (rnn): RNN(100, 256, num_layers=4)\n",
      "  (fc): Linear(in_features=256, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#实例化模型\n",
    "my_module=myRNN()\n",
    "print(my_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 假设对每个时间步进行分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN(nn.Module):\n",
    "    def __init__(self,input_size=100,hidden_size=256,num_layers=4,output_size=3):\n",
    "        super(myRNN,self).__init__()\n",
    "        #创建一个RNN模块\n",
    "        self.rnn=nn.RNN(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)\n",
    "        #输出层单独创建\n",
    "        self.fc=nn.Linear(in_features=hidden_size,out_features=output_size)\n",
    "\n",
    "    def forward(self,X):\n",
    "        output,_=self.rnn(X) #这里我们对hn不做过多关注\n",
    "        output_size=output.reshape(output.shape[0]*output.shape[1],self.hidden_size)#三维转二维\n",
    "        predict=self.fc(output_size)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化参数h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myRNN3(nn.Module):\n",
    "    def __init__(self,input_size=100,hidden_size=256,num_layers=4,output_size=3):\n",
    "        super(myRNN3,self).__init__()\n",
    "        #为了确定h0参数,需要先定义两个属性\n",
    "        self.num_layers=num_layers\n",
    "        self.hidden_size=hidden_size\n",
    "        #创建一个RNN模块\n",
    "        self.rnn=nn.RNN(input_size=input_size,hidden_size=hidden_size,num_layers=num_layers)\n",
    "        #输出层单独创建\n",
    "        self.fc=nn.Linear(in_features=hidden_size,out_features=output_size)\n",
    "\n",
    "    def forward(self,X):\n",
    "        #x.shape=batch_size,seq_size,input_size\n",
    "        #h0.shape=num_layers,batch_size,hidden_size\n",
    "        #初始化h0\n",
    "        h0=torch.zeros(self.num_layers,X.size(0),self.hidden_size)\n",
    "        output,_=self.rnn(X) #这里我们对hn不做过多关注\n",
    "        output_size=output.reshape(output.shape[0]*output.shape[1],self.hidden_size)#三维转二维\n",
    "        predict=self.fc(output_size)\n",
    "        return predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现每个隐藏层上神经元数目不一致的DRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4个隐藏层，前两个有256神经元，后两个512个神经元\n",
    "class myRNN4(nn.Module):\n",
    "    def __init__(self,input_size=100,hidden_size=[256,156,512,512],output_size=3):\n",
    "        super(myRNN4,self).__init__()\n",
    "\n",
    "        #定义四个不同的RNN层\n",
    "        self.rnn1=nn.RNN(input_size,hidden_size[0])\n",
    "        self.rnn2=nn.RNN(hidden_size[0],hidden_size[1])\n",
    "        self.rnn3=nn.RNN(hidden_size[1],hidden_size[2])        \n",
    "        self.rnn4=nn.RNN(hidden_size[2],hidden_size[3])\n",
    "        self.hidden_size=hidden_size\n",
    "\n",
    "        self.linear=nn.Linear(hidden_size[3],output_size)\n",
    "\n",
    "    def forward(self,X):\n",
    "        #x.shape=batch_size,seq_size,input_size\n",
    "        #h0.shape=num_layers,batch_size,hidden_size\n",
    "        #初始化h0\n",
    "        #原来的h0=torch.zeros(self.num_layers,X.size(0),self.hidden_size) \n",
    "        #三维数据：4层隐藏层，3个batch_sieze(x),隐藏层神经元个数\n",
    "        h0=[torch.zeros(1,X.size(0),self.hidden_size[0]),\n",
    "            torch.zeros(1,X.size(0),self.hidden_size[1]),\n",
    "            torch.zeros(1,X.size(0),self.hidden_size[2]),\n",
    "            torch.zeros(1,X.size(0),self.hidden_size[3])\n",
    "            ]\n",
    "        #让输出的X不断进入下一个RNN层\n",
    "        output1,_=self.rnn1(X,h0[0]) #这里我们对hn不做过多关注\n",
    "        output2,_=self.rnn2(output1,h0[1])\n",
    "        output3,_=self.rnn3(output2,h0[2])\n",
    "        output4,_=self.rnn4(output3,h0[3])\n",
    "\n",
    "        #取出最后一个batch结果\n",
    "\n",
    "        output=self.linear(output4[-1,:,:])\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myRNN4(\n",
      "  (rnn1): RNN(100, 256)\n",
      "  (rnn2): RNN(256, 156)\n",
      "  (rnn3): RNN(156, 512)\n",
      "  (rnn4): RNN(512, 512)\n",
      "  (linear): Linear(in_features=512, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model=myRNN4()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
