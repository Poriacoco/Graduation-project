{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 基础"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch 实现反向传播"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 执行一次正向传播后会保存所有中间变量，反向传播中链式法则就是通过这些中间变量相乘，所得即是损失函数对权重参数的偏导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.5379),)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x= torch.tensor(1,requires_grad=True, dtype=torch.float32)\n",
    "z = x**2\n",
    "y= torch.tensor(2,requires_grad=True, dtype=torch.float32)\n",
    "sigma = torch.sigmoid(z)\n",
    "loss =-(y*torch.log(sigma) + (1-y) * torch.log(1-sigma))\n",
    "torch.autograd.grad(loss,x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 定义一个神经网络架构，三分类，500样本20特征，1-13,2-8,out-3(共三层) 激活函数relu和sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确定数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32)\n",
    "y=torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)\n",
    "\n",
    "input_=X.shape[1]\n",
    "output_=len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2.])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8054, 0.1990, 0.9759,  ..., 0.0117, 0.2572, 0.2272],\n",
       "        [0.6076, 0.9066, 0.5540,  ..., 0.8121, 0.0603, 0.7086],\n",
       "        [0.0708, 0.5807, 0.8304,  ..., 0.8998, 0.0322, 0.4390],\n",
       "        ...,\n",
       "        [0.7986, 0.6708, 0.7298,  ..., 0.1268, 0.1310, 0.8556],\n",
       "        [0.6634, 0.8943, 0.9527,  ..., 0.2029, 0.3998, 0.2302],\n",
       "        [0.7081, 0.1069, 0.1263,  ..., 0.0153, 0.4722, 0.0718]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=40,out_features=2):\n",
    "        super().__init__()\n",
    "        self.linear1=nn.Linear(in_features,13,bias=False)\n",
    "        self.linear2=nn.Linear(13,8,False)\n",
    "        self.output=nn.Linear(8,out_features,True)\n",
    "\n",
    "    def forward(self,X):\n",
    "        sigma1=torch.relu(self.linear1(X))\n",
    "        sigma2=torch.sigmoid(self.linear2(sigma1))\n",
    "        z_hat=self.output(sigma2)\n",
    "        return z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "net = Model(input_,output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_hat=net.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "loss= criterion(z_hat,y.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward(retain_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 20])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.1\n",
    "w=net.linear1.weight.data #权重\n",
    "dw=net.linear1.weight.grad #梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "w-=lr*dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8219e-02,\n",
       "         -1.5410e-01,  1.7245e-01,  8.3883e-02, -1.1153e-01, -1.7294e-01,\n",
       "         -1.2947e-01, -4.3139e-02, -1.1413e-01,  1.6294e-01, -9.4083e-02,\n",
       "         -1.4629e-01, -6.8983e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
       "        [ 4.8174e-02,  1.8190e-01,  2.4149e-02, -1.3026e-01,  9.2083e-02,\n",
       "         -9.5210e-02, -1.0582e-01, -4.2824e-02, -1.1669e-01,  2.4615e-02,\n",
       "          1.8153e-01,  3.0533e-02,  1.3506e-01, -1.9422e-01, -1.7593e-01,\n",
       "         -2.9742e-02,  2.0621e-04,  1.3959e-01, -1.9662e-01,  9.3331e-02],\n",
       "        [-1.9184e-01,  3.6138e-02,  1.4793e-01,  3.0939e-02,  7.1511e-02,\n",
       "          1.4233e-01,  2.2135e-01, -1.4023e-01,  7.3449e-02,  1.8421e-01,\n",
       "          1.2732e-01, -2.0247e-01, -1.5496e-01, -2.1887e-01,  9.9163e-02,\n",
       "          2.2131e-01, -2.1647e-01,  1.7898e-01, -2.0911e-01, -2.7156e-02],\n",
       "        [ 1.8145e-01, -3.5160e-02,  2.4802e-02,  1.6301e-01, -1.8755e-01,\n",
       "          5.6598e-02, -1.0910e-01,  2.0525e-01, -1.9378e-01,  1.6908e-02,\n",
       "          1.3967e-01, -1.3137e-01, -1.3200e-01,  7.6557e-02, -1.7558e-01,\n",
       "          1.3097e-01,  2.7187e-02, -2.2009e-01,  7.6896e-02, -1.8730e-01],\n",
       "        [ 2.7512e-02,  1.3708e-01, -3.8641e-02,  8.3551e-02, -1.5557e-02,\n",
       "         -1.6775e-01, -2.1420e-01,  1.8475e-01,  8.3936e-02,  6.0085e-02,\n",
       "         -2.0530e-01, -2.7740e-02,  4.7470e-02, -1.9777e-01, -1.7839e-01,\n",
       "          1.1372e-01,  1.4108e-01, -1.3786e-01,  1.1714e-01, -3.4026e-02],\n",
       "        [ 3.8385e-02, -1.7268e-01, -1.0236e-01, -1.2635e-01, -1.1884e-01,\n",
       "         -1.3463e-01, -1.7610e-01,  3.6539e-02, -1.7834e-01, -1.6471e-01,\n",
       "          2.0834e-01,  1.8400e-01, -8.8726e-02, -7.5382e-02,  1.7876e-01,\n",
       "         -5.7261e-02, -2.4525e-02, -1.1825e-02, -1.8196e-01,  1.9812e-01],\n",
       "        [-2.2033e-02,  2.1846e-01,  1.8414e-01,  9.7156e-02, -5.0743e-03,\n",
       "         -2.4699e-03,  5.1367e-03, -2.1735e-01, -5.3319e-02, -1.0350e-01,\n",
       "         -1.3292e-02,  2.7322e-02, -1.7522e-01,  1.6995e-01,  1.8264e-01,\n",
       "          1.3904e-01,  1.0041e-01,  3.5401e-02, -1.6115e-01,  9.0020e-02],\n",
       "        [ 7.9098e-02,  2.1603e-01, -2.1101e-01,  1.9397e-01,  1.7546e-01,\n",
       "          4.1310e-02,  7.4344e-02,  2.6635e-02, -1.8081e-02,  4.4963e-02,\n",
       "          1.2933e-01,  2.5388e-02, -2.0450e-02, -7.5213e-03, -1.7243e-01,\n",
       "         -1.0711e-01,  1.8188e-01,  1.2995e-02,  2.3336e-02, -1.9577e-01],\n",
       "        [ 1.6342e-01,  8.0601e-03, -2.9876e-02, -2.1881e-01,  1.3477e-01,\n",
       "         -2.8859e-02, -1.8754e-01,  8.9800e-03,  2.0939e-01,  9.0996e-02,\n",
       "         -8.2935e-02, -9.0339e-03,  1.0047e-01, -1.6870e-02, -1.3737e-01,\n",
       "          1.6807e-01, -1.9339e-01, -3.4800e-02,  1.0061e-01,  2.2330e-02],\n",
       "        [ 1.4609e-01,  1.4412e-01, -2.3102e-02,  8.1926e-02,  5.9641e-03,\n",
       "          6.7659e-02,  1.5253e-01,  1.6740e-01, -1.6896e-01,  1.1568e-01,\n",
       "         -1.8539e-01,  2.3307e-02, -1.6148e-01,  1.0229e-01, -1.7314e-01,\n",
       "         -1.8908e-01, -2.0287e-01, -2.1226e-02, -2.1813e-02, -3.7939e-02],\n",
       "        [ 1.9374e-01,  5.3913e-02, -1.4901e-01,  1.6708e-01, -1.6652e-01,\n",
       "          6.2357e-02, -4.1572e-02, -2.0565e-01, -1.3650e-01, -2.0600e-01,\n",
       "         -1.9033e-01, -8.8944e-02, -7.8063e-02,  1.6323e-01, -1.3175e-01,\n",
       "          5.8634e-02,  2.1116e-01,  1.6706e-01, -5.9501e-02, -2.0974e-01],\n",
       "        [-2.5612e-02, -1.0767e-02, -3.2995e-02,  3.7114e-02, -1.0804e-01,\n",
       "          2.0648e-01,  1.2401e-01, -2.1518e-01,  1.2181e-01, -1.4319e-01,\n",
       "          1.1339e-01,  4.6965e-02,  8.4610e-02,  2.0535e-01, -1.1825e-01,\n",
       "          1.9290e-01, -2.8345e-02,  7.2208e-03, -2.1050e-01,  1.0808e-01],\n",
       "        [-1.2258e-01, -6.8328e-02, -2.1929e-01, -1.4940e-01,  1.9225e-01,\n",
       "         -6.2928e-02, -7.6381e-02,  2.1954e-01, -4.5841e-02,  9.7911e-03,\n",
       "         -2.9451e-03, -9.5246e-02, -7.9778e-02, -1.8709e-01,  1.7828e-01,\n",
       "         -1.7552e-01, -1.0328e-01, -1.9706e-02, -1.7449e-01,  2.0404e-02]])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v(t)=gamma * v(t-1) - lr*dw\n",
    "# w(t+1)=w(t)+v(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.1\n",
    "gamma=0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "dw=net.linear1.weight.grad\n",
    "w=net.linear1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=torch.zeros(dw.shape[0],dw.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "v=gamma*v-lr*dw\n",
    "w+= v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3655e-01, -1.3459e-01,  2.1280e-01, -1.7763e-01, -6.8220e-02,\n",
       "         -1.5410e-01,  1.7245e-01,  8.3881e-02, -1.1153e-01, -1.7294e-01,\n",
       "         -1.2947e-01, -4.3140e-02, -1.1413e-01,  1.6294e-01, -9.4084e-02,\n",
       "         -1.4629e-01, -6.8984e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
       "        [ 4.8221e-02,  1.8193e-01,  2.4150e-02, -1.3021e-01,  9.2109e-02,\n",
       "         -9.5217e-02, -1.0580e-01, -4.2795e-02, -1.1670e-01,  2.4650e-02,\n",
       "          1.8154e-01,  3.0567e-02,  1.3505e-01, -1.9419e-01, -1.7594e-01,\n",
       "         -2.9734e-02,  2.0757e-04,  1.3962e-01, -1.9658e-01,  9.3368e-02],\n",
       "        [-1.9175e-01,  3.6205e-02,  1.4808e-01,  3.1034e-02,  7.1630e-02,\n",
       "          1.4250e-01,  2.2148e-01, -1.4013e-01,  7.3642e-02,  1.8432e-01,\n",
       "          1.2747e-01, -2.0242e-01, -1.5483e-01, -2.1875e-01,  9.9346e-02,\n",
       "          2.2138e-01, -2.1635e-01,  1.7915e-01, -2.0900e-01, -2.7037e-02],\n",
       "        [ 1.8145e-01, -3.5155e-02,  2.4803e-02,  1.6302e-01, -1.8755e-01,\n",
       "          5.6608e-02, -1.0909e-01,  2.0526e-01, -1.9377e-01,  1.6917e-02,\n",
       "          1.3968e-01, -1.3137e-01, -1.3200e-01,  7.6561e-02, -1.7558e-01,\n",
       "          1.3099e-01,  2.7192e-02, -2.2008e-01,  7.6910e-02, -1.8728e-01],\n",
       "        [ 2.7606e-02,  1.3717e-01, -3.8596e-02,  8.3639e-02, -1.5481e-02,\n",
       "         -1.6769e-01, -2.1414e-01,  1.8488e-01,  8.3981e-02,  6.0221e-02,\n",
       "         -2.0522e-01, -2.7649e-02,  4.7497e-02, -1.9773e-01, -1.7836e-01,\n",
       "          1.1381e-01,  1.4115e-01, -1.3779e-01,  1.1724e-01, -3.3945e-02],\n",
       "        [ 3.8382e-02, -1.7268e-01, -1.0236e-01, -1.2635e-01, -1.1884e-01,\n",
       "         -1.3463e-01, -1.7610e-01,  3.6535e-02, -1.7834e-01, -1.6471e-01,\n",
       "          2.0833e-01,  1.8399e-01, -8.8729e-02, -7.5386e-02,  1.7876e-01,\n",
       "         -5.7263e-02, -2.4527e-02, -1.1828e-02, -1.8196e-01,  1.9811e-01],\n",
       "        [-2.2055e-02,  2.1845e-01,  1.8418e-01,  9.7134e-02, -5.0853e-03,\n",
       "         -2.4667e-03,  5.1325e-03, -2.1737e-01, -5.3264e-02, -1.0353e-01,\n",
       "         -1.3282e-02,  2.7290e-02, -1.7521e-01,  1.6995e-01,  1.8270e-01,\n",
       "          1.3901e-01,  1.0042e-01,  3.5424e-02, -1.6117e-01,  8.9983e-02],\n",
       "        [ 7.8964e-02,  2.1592e-01, -2.1116e-01,  1.9386e-01,  1.7533e-01,\n",
       "          4.1149e-02,  7.4206e-02,  2.6532e-02, -1.8290e-02,  4.4886e-02,\n",
       "          1.2919e-01,  2.5292e-02, -2.0581e-02, -7.6483e-03, -1.7264e-01,\n",
       "         -1.0717e-01,  1.8174e-01,  1.2810e-02,  2.3203e-02, -1.9586e-01],\n",
       "        [ 1.6346e-01,  8.0993e-03, -2.9867e-02, -2.1878e-01,  1.3482e-01,\n",
       "         -2.8817e-02, -1.8751e-01,  9.0344e-03,  2.0938e-01,  9.1065e-02,\n",
       "         -8.2901e-02, -8.9786e-03,  1.0048e-01, -1.6844e-02, -1.3737e-01,\n",
       "          1.6813e-01, -1.9335e-01, -3.4778e-02,  1.0065e-01,  2.2388e-02],\n",
       "        [ 1.4608e-01,  1.4410e-01, -2.3110e-02,  8.1906e-02,  5.9491e-03,\n",
       "          6.7646e-02,  1.5252e-01,  1.6739e-01, -1.6897e-01,  1.1566e-01,\n",
       "         -1.8540e-01,  2.3298e-02, -1.6150e-01,  1.0228e-01, -1.7314e-01,\n",
       "         -1.8910e-01, -2.0289e-01, -2.1241e-02, -2.1826e-02, -3.7956e-02],\n",
       "        [ 1.9373e-01,  5.3904e-02, -1.4902e-01,  1.6707e-01, -1.6652e-01,\n",
       "          6.2350e-02, -4.1569e-02, -2.0565e-01, -1.3651e-01, -2.0600e-01,\n",
       "         -1.9033e-01, -8.8946e-02, -7.8065e-02,  1.6323e-01, -1.3176e-01,\n",
       "          5.8630e-02,  2.1114e-01,  1.6705e-01, -5.9510e-02, -2.0975e-01],\n",
       "        [-2.5580e-02, -1.0715e-02, -3.2940e-02,  3.7157e-02, -1.0798e-01,\n",
       "          2.0655e-01,  1.2407e-01, -2.1513e-01,  1.2190e-01, -1.4315e-01,\n",
       "          1.1344e-01,  4.6999e-02,  8.4668e-02,  2.0540e-01, -1.1818e-01,\n",
       "          1.9294e-01, -2.8292e-02,  7.2973e-03, -2.1046e-01,  1.0812e-01],\n",
       "        [-1.2258e-01, -6.8332e-02, -2.1929e-01, -1.4940e-01,  1.9224e-01,\n",
       "         -6.2934e-02, -7.6386e-02,  2.1953e-01, -4.5844e-02,  9.7811e-03,\n",
       "         -2.9501e-03, -9.5250e-02, -7.9781e-02, -1.8709e-01,  1.7827e-01,\n",
       "         -1.7552e-01, -1.0329e-01, -1.9715e-02, -1.7450e-01,  2.0400e-02]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.optim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入库\n",
    "# 确定数据，超参数\n",
    "# 定义神经网络架构\n",
    "# 实例化神经网络的类-正向传播\n",
    "# 定义损失函数\n",
    "# 定义优化算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32)\n",
    "y=torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)\n",
    "\n",
    "lr=0.1\n",
    "gamma=0.9\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \"\"\"定义一个神经网络架构,三分类,500样本20特征,1-13,2-8,out-3(共三层) 激活函数relu和sigmoid\"\"\"\n",
    "    def __init__(self,in_features=40,out_features=2):\n",
    "        super().__init__()\n",
    "        self.linear1=nn.Linear(in_features,13,bias=False)\n",
    "        self.linear2=nn.Linear(13,8,False)\n",
    "        self.output=nn.Linear(8,out_features,True)\n",
    "\n",
    "    def forward(self,X):\n",
    "        sigma1=torch.relu(self.linear1(X))\n",
    "        sigma2=torch.sigmoid(self.linear2(sigma1))\n",
    "        z_hat=self.output(sigma2)\n",
    "        return z_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_=X.shape[1]\n",
    "output_=len(y.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "net=Model(in_features=input_,out_features=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8218e-02,\n",
      "         -1.5410e-01,  1.7245e-01,  8.3885e-02, -1.1153e-01, -1.7294e-01,\n",
      "         -1.2947e-01, -4.3138e-02, -1.1413e-01,  1.6295e-01, -9.4082e-02,\n",
      "         -1.4629e-01, -6.8982e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
      "        [ 4.8127e-02,  1.8186e-01,  2.4149e-02, -1.3032e-01,  9.2056e-02,\n",
      "         -9.5202e-02, -1.0584e-01, -4.2852e-02, -1.1669e-01,  2.4581e-02,\n",
      "          1.8152e-01,  3.0500e-02,  1.3506e-01, -1.9425e-01, -1.7591e-01,\n",
      "         -2.9751e-02,  2.0485e-04,  1.3957e-01, -1.9666e-01,  9.3293e-02],\n",
      "        [-1.9192e-01,  3.6070e-02,  1.4778e-01,  3.0845e-02,  7.1393e-02,\n",
      "          1.4217e-01,  2.2122e-01, -1.4032e-01,  7.3255e-02,  1.8409e-01,\n",
      "          1.2716e-01, -2.0253e-01, -1.5509e-01, -2.1899e-01,  9.8980e-02,\n",
      "          2.2123e-01, -2.1659e-01,  1.7880e-01, -2.0922e-01, -2.7275e-02],\n",
      "        [ 1.8144e-01, -3.5166e-02,  2.4801e-02,  1.6299e-01, -1.8755e-01,\n",
      "          5.6587e-02, -1.0911e-01,  2.0523e-01, -1.9378e-01,  1.6899e-02,\n",
      "          1.3966e-01, -1.3137e-01, -1.3201e-01,  7.6554e-02, -1.7558e-01,\n",
      "          1.3096e-01,  2.7182e-02, -2.2010e-01,  7.6883e-02, -1.8731e-01],\n",
      "        [ 2.7419e-02,  1.3699e-01, -3.8687e-02,  8.3463e-02, -1.5634e-02,\n",
      "         -1.6781e-01, -2.1426e-01,  1.8463e-01,  8.3891e-02,  5.9950e-02,\n",
      "         -2.0538e-01, -2.7832e-02,  4.7442e-02, -1.9782e-01, -1.7842e-01,\n",
      "          1.1362e-01,  1.4101e-01, -1.3794e-01,  1.1704e-01, -3.4108e-02],\n",
      "        [ 3.8388e-02, -1.7268e-01, -1.0235e-01, -1.2634e-01, -1.1883e-01,\n",
      "         -1.3463e-01, -1.7610e-01,  3.6543e-02, -1.7834e-01, -1.6471e-01,\n",
      "          2.0834e-01,  1.8400e-01, -8.8723e-02, -7.5378e-02,  1.7877e-01,\n",
      "         -5.7259e-02, -2.4522e-02, -1.1822e-02, -1.8196e-01,  1.9812e-01],\n",
      "        [-2.2011e-02,  2.1847e-01,  1.8410e-01,  9.7177e-02, -5.0634e-03,\n",
      "         -2.4731e-03,  5.1408e-03, -2.1733e-01, -5.3375e-02, -1.0346e-01,\n",
      "         -1.3303e-02,  2.7354e-02, -1.7523e-01,  1.6994e-01,  1.8259e-01,\n",
      "          1.3907e-01,  1.0041e-01,  3.5377e-02, -1.6114e-01,  9.0056e-02],\n",
      "        [ 7.9232e-02,  2.1614e-01, -2.1087e-01,  1.9407e-01,  1.7559e-01,\n",
      "          4.1470e-02,  7.4482e-02,  2.6737e-02, -1.7872e-02,  4.5040e-02,\n",
      "          1.2947e-01,  2.5483e-02, -2.0320e-02, -7.3942e-03, -1.7221e-01,\n",
      "         -1.0705e-01,  1.8203e-01,  1.3179e-02,  2.3468e-02, -1.9567e-01],\n",
      "        [ 1.6338e-01,  8.0209e-03, -2.9885e-02, -2.1884e-01,  1.3471e-01,\n",
      "         -2.8901e-02, -1.8757e-01,  8.9256e-03,  2.0940e-01,  9.0927e-02,\n",
      "         -8.2969e-02, -9.0893e-03,  1.0047e-01, -1.6897e-02, -1.3736e-01,\n",
      "          1.6801e-01, -1.9342e-01, -3.4822e-02,  1.0057e-01,  2.2273e-02],\n",
      "        [ 1.4611e-01,  1.4414e-01, -2.3093e-02,  8.1946e-02,  5.9792e-03,\n",
      "          6.7672e-02,  1.5254e-01,  1.6742e-01, -1.6896e-01,  1.1571e-01,\n",
      "         -1.8538e-01,  2.3316e-02, -1.6147e-01,  1.0230e-01, -1.7314e-01,\n",
      "         -1.8906e-01, -2.0286e-01, -2.1210e-02, -2.1799e-02, -3.7921e-02],\n",
      "        [ 1.9375e-01,  5.3921e-02, -1.4900e-01,  1.6709e-01, -1.6652e-01,\n",
      "          6.2363e-02, -4.1574e-02, -2.0565e-01, -1.3649e-01, -2.0600e-01,\n",
      "         -1.9032e-01, -8.8942e-02, -7.8061e-02,  1.6323e-01, -1.3174e-01,\n",
      "          5.8638e-02,  2.1117e-01,  1.6707e-01, -5.9492e-02, -2.0973e-01],\n",
      "        [-2.5644e-02, -1.0818e-02, -3.3051e-02,  3.7071e-02, -1.0809e-01,\n",
      "          2.0642e-01,  1.2396e-01, -2.1523e-01,  1.2172e-01, -1.4323e-01,\n",
      "          1.1334e-01,  4.6931e-02,  8.4553e-02,  2.0530e-01, -1.1833e-01,\n",
      "          1.9287e-01, -2.8398e-02,  7.1443e-03, -2.1055e-01,  1.0805e-01],\n",
      "        [-1.2258e-01, -6.8325e-02, -2.1929e-01, -1.4939e-01,  1.9226e-01,\n",
      "         -6.2922e-02, -7.6377e-02,  2.1955e-01, -4.5838e-02,  9.8011e-03,\n",
      "         -2.9400e-03, -9.5241e-02, -7.9775e-02, -1.8708e-01,  1.7828e-01,\n",
      "         -1.7552e-01, -1.0328e-01, -1.9697e-02, -1.7449e-01,  2.0408e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.6755e-01,  1.9149e-01, -2.4001e-01, -8.5307e-02,  1.7100e-01,\n",
      "         -2.2915e-01,  1.5830e-01,  2.2365e-01,  1.1802e-01, -1.5703e-01,\n",
      "          1.7758e-01, -1.8538e-01,  4.2498e-05],\n",
      "        [-8.5420e-02,  8.2520e-02,  1.0203e-01, -9.4093e-02,  2.0539e-01,\n",
      "          2.6446e-01, -2.1979e-01, -1.6906e-02,  1.6783e-03, -2.7140e-01,\n",
      "         -1.1539e-01,  4.1025e-02, -6.6782e-02],\n",
      "        [-2.6677e-01,  1.7521e-01, -2.7429e-01,  1.6111e-01, -1.1903e-01,\n",
      "          4.7583e-02,  3.5949e-03,  2.1846e-01, -1.0215e-01,  2.3968e-01,\n",
      "          1.0545e-01, -7.0437e-02, -1.4198e-01],\n",
      "        [ 2.2488e-01, -2.5628e-01, -2.1212e-01, -6.7781e-02,  1.1293e-01,\n",
      "          3.4885e-03,  9.8788e-02,  2.4942e-01,  1.8909e-01, -4.4837e-02,\n",
      "          1.5829e-01,  1.2611e-02,  2.2197e-01],\n",
      "        [-2.0947e-01, -1.9380e-01, -5.6165e-02, -2.1829e-01, -2.4831e-01,\n",
      "          2.0776e-01,  2.1416e-01,  7.5449e-02, -2.5317e-01,  1.1419e-01,\n",
      "          6.5725e-02, -8.0840e-02,  2.7254e-01],\n",
      "        [ 2.0634e-01,  8.6954e-02, -2.6413e-01,  2.6480e-01,  1.4430e-01,\n",
      "         -2.7592e-01,  1.0140e-02,  1.6106e-01,  2.4885e-01, -1.1753e-01,\n",
      "          5.3666e-02, -3.6536e-02,  2.0949e-01],\n",
      "        [ 2.3334e-01, -1.4785e-02, -2.4399e-01,  2.6847e-02,  1.8149e-01,\n",
      "          2.5284e-01, -2.7302e-01,  2.1448e-01,  2.0513e-02, -2.2786e-01,\n",
      "          7.2713e-02, -2.3087e-01, -1.7545e-01],\n",
      "        [-1.6444e-01, -5.0759e-02,  5.4837e-02,  7.0175e-02, -1.8667e-01,\n",
      "         -8.1848e-02,  2.0409e-01, -2.6876e-02, -1.0984e-01, -4.6356e-02,\n",
      "          1.5113e-01,  5.0004e-03, -1.3636e-01]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.2778, -0.0133,  0.1872, -0.0716, -0.2917, -0.1173,  0.2174, -0.2389],\n",
      "        [-0.1349, -0.1043, -0.3350, -0.3471,  0.2512,  0.1148, -0.0760,  0.0342],\n",
      "        [-0.0220,  0.0083,  0.0290, -0.1795,  0.1515,  0.1259,  0.1116, -0.0097]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1100,  0.0427,  0.3335], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for a in net.parameters():\n",
    "    print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt=optim.SGD(net.parameters(),lr=lr,momentum=gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向前传播\n",
    "# 损失函数值\n",
    "# 反向传播得到梯度\n",
    "# 更新权重和动量\n",
    "# 清空梯度-清除上一个坐标的梯度节省内存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2., 0., 2., 0., 1., 0., 1., 2., 1., 0., 0., 2., 0., 2., 1., 1.,\n",
       "        1., 1., 2., 0., 2., 2., 1., 0., 1., 2., 2., 2., 0., 2., 2., 0., 1., 2.,\n",
       "        2., 2., 1., 1., 2., 2., 0., 0., 1., 1., 2., 1., 0., 0., 0., 1., 2., 1.,\n",
       "        1., 1., 2., 1., 0., 1., 1., 2., 2., 2., 1., 0., 2., 1., 1., 1., 2., 1.,\n",
       "        1., 1., 1., 1., 0., 0., 0., 1., 0., 2., 2., 2., 2., 2., 0., 1., 1., 0.,\n",
       "        0., 1., 2., 1., 2., 0., 0., 0., 2., 2., 0., 0., 2., 1., 1., 1., 2., 2.,\n",
       "        0., 1., 1., 0., 2., 0., 2., 1., 1., 2., 0., 0., 1., 0., 0., 2., 1., 2.,\n",
       "        2., 2., 1., 0., 1., 1., 0., 1., 1., 0., 0., 1., 0., 2., 1., 0., 0., 1.,\n",
       "        1., 0., 0., 1., 1., 1., 2., 2., 0., 1., 0., 2., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 1., 1., 2., 1., 2., 2., 0., 2., 0., 2., 0., 1., 1., 2., 0., 1.,\n",
       "        2., 1., 0., 1., 1., 0., 2., 1., 1., 2., 1., 0., 1., 0., 1., 1., 1., 2.,\n",
       "        0., 2., 1., 2., 0., 2., 2., 1., 1., 2., 1., 0., 2., 1., 2., 0., 1., 1.,\n",
       "        0., 1., 2., 1., 2., 2., 0., 1., 2., 1., 1., 0., 1., 2., 1., 1., 0., 2.,\n",
       "        0., 2., 2., 2., 1., 1., 1., 2., 0., 2., 2., 1., 1., 0., 2., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 2., 2., 1., 0., 2., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 2., 0., 0., 1., 0., 1., 1., 2., 0., 0., 0., 0., 0., 1.,\n",
       "        1., 1., 2., 0., 2., 1., 2., 2., 1., 0., 2., 0., 0., 2., 0., 2., 0., 0.,\n",
       "        0., 1., 0., 2., 0., 2., 2., 1., 1., 2., 2., 1., 1., 2., 0., 1., 2., 2.,\n",
       "        0., 2., 2., 2., 0., 0., 2., 1., 1., 0., 1., 0., 0., 2., 0., 1., 1., 0.,\n",
       "        1., 0., 1., 1., 2., 1., 2., 0., 1., 2., 1., 2., 0., 2., 0., 2., 2., 1.,\n",
       "        0., 0., 2., 2., 2., 2., 1., 0., 0., 2., 1., 1., 1., 2., 0., 0., 1., 2.,\n",
       "        1., 0., 2., 2., 1., 2., 0., 0., 1., 1., 2., 0., 0., 1., 2., 2., 2., 1.,\n",
       "        2., 0., 1., 0., 1., 0., 2., 0., 0., 0., 2., 2., 1., 1., 0., 1., 2., 0.,\n",
       "        1., 1., 2., 2., 2., 0., 2., 0., 1., 2., 0., 2., 2., 1., 1., 1., 2., 2.,\n",
       "        2., 0., 2., 0., 1., 2., 1., 0., 2., 0., 2., 2., 0., 0., 2., 0., 1., 2.,\n",
       "        1., 2., 0., 0., 2., 1., 2., 1., 2., 0., 1., 1., 0., 1., 0., 0., 2., 2.,\n",
       "        0., 1., 0., 2., 0., 1., 2., 1., 2., 1., 0., 0., 0., 2., 2., 1., 1., 0.,\n",
       "        0., 0., 1., 0., 0., 2., 0., 0., 2., 1., 0., 2., 1., 1.])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1535, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 0.1366, -0.1346,  0.2128, -0.1776, -0.0682, -0.1541,  0.1724,  0.0839,\n",
      "        -0.1115, -0.1729])\n"
     ]
    }
   ],
   "source": [
    "z_hat= net.forward(X)\n",
    "loss=criterion(z_hat,y.reshape(500).long())\n",
    "loss.backward()\n",
    "opt.step() #步子，走一步更新权重w,更新动量v\n",
    "opt.zero_grad() #清空梯度\n",
    "print(loss)\n",
    "print(net.linear1.weight.data[0][:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorDataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.randn(500,2,3) # 二维表\n",
    "b=torch.randn(500,3,4,5) # 图像数据\n",
    "c=torch.randn(500,1)  # 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x131160490>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合并，要求被合并张量第一维度（样本数）相等\n",
    "TensorDataset(a,b,c) # generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[ 0.0555,  0.0347, -0.0640],\n",
      "        [-0.6151,  0.5850, -1.3424]]), tensor([[[ 1.4229,  0.3269, -0.7064,  0.4886, -0.4457],\n",
      "         [-0.1819,  1.3381, -0.0515,  0.9612,  0.6173],\n",
      "         [ 2.1468,  0.0329, -1.3354, -0.2216, -1.2585],\n",
      "         [-0.0606, -0.7752,  1.5580,  0.8701,  2.0751]],\n",
      "\n",
      "        [[-0.4195,  0.3641,  1.1461,  1.3315,  0.6182],\n",
      "         [ 0.4945,  0.4110,  0.4114, -1.9308, -0.2237],\n",
      "         [ 0.4374,  0.4338,  0.5920,  0.7556, -0.4258],\n",
      "         [ 1.5789, -0.1794, -0.5889,  1.8905, -0.7718]],\n",
      "\n",
      "        [[-0.7557, -1.2767,  1.0856,  0.7704,  2.3633],\n",
      "         [ 0.0490, -0.9121, -0.0489, -1.2371, -1.2507],\n",
      "         [-2.2677, -0.1536, -0.2799, -0.9272,  1.4546],\n",
      "         [-0.8360, -0.3864, -0.9757, -0.5694,  0.2240]]]), tensor([-0.1178]))\n"
     ]
    }
   ],
   "source": [
    "for x in TensorDataset(a,b,c):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader -用来切割小批量的类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x131160eb0>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=TensorDataset(b,c)\n",
    "DataLoader(data) #generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[ 1.4229,  0.3269, -0.7064,  0.4886, -0.4457],\n",
      "          [-0.1819,  1.3381, -0.0515,  0.9612,  0.6173],\n",
      "          [ 2.1468,  0.0329, -1.3354, -0.2216, -1.2585],\n",
      "          [-0.0606, -0.7752,  1.5580,  0.8701,  2.0751]],\n",
      "\n",
      "         [[-0.4195,  0.3641,  1.1461,  1.3315,  0.6182],\n",
      "          [ 0.4945,  0.4110,  0.4114, -1.9308, -0.2237],\n",
      "          [ 0.4374,  0.4338,  0.5920,  0.7556, -0.4258],\n",
      "          [ 1.5789, -0.1794, -0.5889,  1.8905, -0.7718]],\n",
      "\n",
      "         [[-0.7557, -1.2767,  1.0856,  0.7704,  2.3633],\n",
      "          [ 0.0490, -0.9121, -0.0489, -1.2371, -1.2507],\n",
      "          [-2.2677, -0.1536, -0.2799, -0.9272,  1.4546],\n",
      "          [-0.8360, -0.3864, -0.9757, -0.5694,  0.2240]]]]), tensor([[-0.1178]])]\n"
     ]
    }
   ],
   "source": [
    "for x in DataLoader(data):\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=DataLoader(data\n",
    "           ,batch_size=bs\n",
    "           ,shuffle=True  # 随机打乱\n",
    "           ,drop_last=False #舍弃最后一个batch\n",
    "          )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x131160c10>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x131160f10>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([120, 3, 4, 5])\n",
      "torch.Size([20, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "for x in dataset:\n",
    "    print(x[0].shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) #多少个batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x131160c10>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset #展示数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset.dataset) # 多少样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 5])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[499] #单个样本\n",
    "dataset.dataset[499][0] #单个样本的特征张量\n",
    "dataset.dataset[499][0].shape #单个样本的特征张量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.dataset[0][0].shape\n",
    "dataset.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2],\n",
       "        [ 3,  4,  5],\n",
       "        [ 6,  7,  8],\n",
       "        [ 9, 10, 11]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t =torch.arange(12).reshape(4,3)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x1310aa850>,\n",
       " <torch.utils.data.dataset.Subset at 0x1310aa400>]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_split(t,[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test=random_split(t,[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 9, 10, 11]) tensor([6, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "for tr,te in random_split(t,[2,2]):\n",
    "    print(tr,te)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorDataset 封装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "features,labels=tensorGenCla(num_class=2)\n",
    "labels=labels.float()\n",
    "data=TensorDataset(features,labels)\n",
    "batch_data=DataLoader(data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义并实例化Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LBCDataset(Dataset):\n",
    "    def __init__(self,data):\n",
    "        self.features=features\n",
    "        self.labels=labels\n",
    "        self.lens=len(data.data)\n",
    "    def __getitem__(self,index):\n",
    "        return self.features[index,:],self.labels[index]\n",
    "    def __len__(self):\n",
    "        return self.lens\n",
    "    \n",
    "data=LBC()\n",
    "LBC_data=LBCDataset(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randm_split 进行切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randm_split 进行切分\n",
    "num_train=int(LBC_data.len*0.7)\n",
    "num_test=LBC_data.len-num_train\n",
    "LBC_train,LBC_test=random_split(LBC_data,[num_train,num_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .dataset 可以用于切分后数据集的还原\n",
    "LBC_train.dataset==LBC_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader 装载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(LBC_train,batch_size=10,shuffer=True)\n",
    "test_loader=DataLoader(LBC_test,batch_size=10,shuffer=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch_normalization处理 & BN层添加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "module() takes at most 2 arguments (3 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[226], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 创建一个两层神经网络，BN层可选，激活函数可选\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mnet_class1\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mmodules):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,act_fun\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mrelu,in_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,n_hidden\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,out_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,bias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m,BN_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28msuper\u001b[39m(net_class1,\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
      "\u001b[0;31mTypeError\u001b[0m: module() takes at most 2 arguments (3 given)"
     ]
    }
   ],
   "source": [
    "# 创建一个两层神经网络，BN层可选，激活函数可选\n",
    "class net_class1(nn.modules):\n",
    "    def __init__(self,act_fun=torch.relu,in_features=2,n_hidden=4,out_features=1,bias=True,momentum=0.1,BN_model=None):\n",
    "        super(net_class1,self).__init__()\n",
    "        self.linear1=nn.Linear(in_features,n_hidden,bias=bias)\n",
    "        self.normalize1=nn.BatchNorm1d(n_hidden,momentum=momentum)\n",
    "        self.linear2=nn.Linear(n_hidden,out_features,bias=bias)\n",
    "        self.BN_model=BN_model\n",
    "        self.act_fun=act_fun\n",
    "\n",
    "    def forward(self,x):\n",
    "        if self.BN_model == None:\n",
    "            z1=self.linear1(x)\n",
    "            p1=self.act_fun(z1)\n",
    "            out=self.linear2(p1)\n",
    "        elif self.BN_model=='pre':\n",
    "            z1=self.normalize1(self.linear1(x))\n",
    "            p1=self.act_fun(z1)\n",
    "            out=self.linear2(p1)\n",
    "        elif self.BN_model=='post':\n",
    "            z1=self.linear1(x)\n",
    "            p1=self.act_fun(z1)\n",
    "            out=self.normalize1(self.linear2(p1))\n",
    "        \n",
    "        return out\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
