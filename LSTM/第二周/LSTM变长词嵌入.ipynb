{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_1_x = ['is', 'it', 'too', 'late', 'now', 'say', 'sorry']\n",
    "sent_1_y = ['VB', 'PRP', 'RB', 'RB', 'RB', 'VB', 'JJ']\n",
    "sent_2_x = ['ooh', 'ooh']\n",
    "sent_2_y = ['NNP', 'NNP']\n",
    "sent_3_x = ['sorry', 'yeah']\n",
    "sent_3_y = ['JJ', 'NNP']\n",
    "X = [sent_1_x, sent_2_x, sent_3_x]\n",
    "Y = [sent_1_y, sent_2_y, sent_3_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['is', 'it', 'too', 'late', 'now', 'say', 'sorry'],\n",
       " ['ooh', 'ooh'],\n",
       " ['sorry', 'yeah']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map sentences to vocab\n",
    "vocab = {'<PAD>': 0, 'is': 1, 'it': 2, 'too': 3, 'late': 4, 'now': 5, 'say': 6, 'sorry': 7, 'ooh': 8, 'yeah': 9} \n",
    "# fancy nested list comprehension\n",
    "X =  [[vocab[word] for word in sentence] for sentence in X]\n",
    "# X now looks like:  \n",
    "# [[1, 2, 3, 4, 5, 6, 7], [8, 8], [7, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, 4, 5, 6, 7], [8, 8], [7, 9]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = {'<PAD>': 0, 'VB': 1, 'PRP': 2, 'RB': 3, 'JJ': 4, 'NNP': 5}\n",
    "# fancy nested list comprehension\n",
    "Y =  [[tags[tag] for tag in sentence] for sentence in Y]\n",
    "# Y now looks like:\n",
    "# [[1, 2, 3, 3, 3, 1, 4], [5, 5], [4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = [[0, 1, 2, 3, 4, 5, 6], \n",
    "    [7, 7], \n",
    "    [6, 8]]\n",
    "# get the length of each sentence\n",
    "X_lengths = [len(sentence) for sentence in X]\n",
    "# create an empty matrix with padding tokens\n",
    "pad_token = vocab['<PAD>']\n",
    "longest_sent = max(X_lengths)\n",
    "batch_size = len(X)\n",
    "padded_X = np.ones((batch_size, longest_sent)) * pad_token\n",
    "padded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 2., 3., 4., 5., 6.],\n",
       "       [7., 7., 0., 0., 0., 0., 0.],\n",
       "       [6., 8., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# copy over the actual sequences\n",
    "for i, x_len in enumerate(X_lengths):\n",
    "  sequence = X[i]\n",
    "  padded_X[i, 0:x_len] = sequence[:x_len]\n",
    "padded_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
